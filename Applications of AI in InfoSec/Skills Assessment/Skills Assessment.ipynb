{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a1dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Extract the dataset\n",
    "with zipfile.ZipFile('skills_assessment_data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "# Explore the extracted files\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv') or file.endswith('.txt'):\n",
    "            print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33bbc202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (25000, 2)\n",
      "Test data shape:     (25000, 2)\n",
      "\n",
      "Columns in training data: ['text', 'label']\n",
      "\n",
      "Label distribution (train):\n",
      "label\n",
      "1    12500\n",
      "0    12500\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Sample training row:\n",
      "                                                text  label\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
      "1  Homelessness (or Houselessness as George Carli...      1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 1.1) Read train.json and test.json into DataFrames\n",
    "with open('train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df  = pd.DataFrame(test_data)\n",
    "\n",
    "# 1.2) Quick sanity checks\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape:     {test_df.shape}\\n\")\n",
    "\n",
    "print(\"Columns in training data:\", train_df.columns.tolist())\n",
    "print(\"\\nLabel distribution (train):\")\n",
    "print(train_df['label'].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"Sample training row:\")\n",
    "print(train_df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6a7b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original vs. Preprocessed ===\n",
      "\n",
      "Sample 1 original (first 100 chars):\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life,…\n",
      "Sample 1 cleaned:              \n",
      "bromwell high is a cartoon comedy it ran at the same time as some other programs about school life s…\n",
      "\n",
      "Sample 2 original (first 100 chars):\n",
      "Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan…\n",
      "Sample 2 cleaned:              \n",
      "homelessness or houselessness as george carlin stated has been an issue for years but never a plan t…\n",
      "\n",
      "Sample 3 original (first 100 chars):\n",
      "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that…\n",
      "Sample 3 cleaned:              \n",
      "i went and saw this movie last night after being coaxed to by a few friends of mine i ll admit that …\n",
      "\n",
      "Sample 4 original (first 100 chars):\n",
      "Actor turned director Bill Paxton follows up his promising debut, the Gothic-horror \"Frailty\", with …\n",
      "Sample 4 cleaned:              \n",
      "actor turned director bill paxton follows up his promising debut the gothic horror frailty with this…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    # 2.1) Lowercase\n",
    "    text = text.lower()\n",
    "    # 2.2) Strip HTML tags like \"<br />\"\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    # 2.3) Remove all non-letter characters, leaving only a–z and spaces\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    # 2.4) Collapse multiple spaces into one\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# 2.5) Test on a few samples from train_df and test_df\n",
    "samples = [\n",
    "    train_df['text'].iloc[0],\n",
    "    train_df['text'].iloc[1],\n",
    "    test_df['text'].iloc[0],\n",
    "    test_df['text'].iloc[1]\n",
    "]\n",
    "\n",
    "print(\"=== Original vs. Preprocessed ===\\n\")\n",
    "for i, raw in enumerate(samples):\n",
    "    cleaned = preprocess_text(raw)\n",
    "    print(f\"Sample {i+1} original (first 100 chars):\\n{raw[:100]}…\")\n",
    "    print(f\"Sample {i+1} cleaned:              \\n{cleaned[:100]}…\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae185ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shapes ➞ Train: (25000, 10000),  Test: (25000, 10000)\n",
      "Fraction of test rows with zero TF-IDF features: 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 3.1) Create the TF-IDF vectorizer (using our preprocess_text from Stage 2)\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    preprocessor=preprocess_text,  # calls our function automatically\n",
    "    max_features=10000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.8\n",
    ")\n",
    "\n",
    "# 3.2) Fit on all training reviews and transform both train and portal test\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "X_test_tfidf  = tfidf_vectorizer.transform(test_df['text'])\n",
    "\n",
    "print(f\"TF-IDF shapes ➞ Train: {X_train_tfidf.shape},  Test: {X_test_tfidf.shape}\")\n",
    "\n",
    "# 3.3) Check how many test rows became “all-zero” vectors\n",
    "nonzero_counts = X_test_tfidf.getnnz(axis=1)        # number of nonzero components per row\n",
    "zero_fraction  = np.mean(nonzero_counts == 0)       # fraction with no nonzero terms\n",
    "print(f\"Fraction of test rows with zero TF-IDF features: {zero_fraction:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b6db6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local validation accuracy: 0.8754\n",
      "\n",
      "Classification Report (local 20%):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87      2500\n",
      "    positive       0.87      0.89      0.88      2500\n",
      "\n",
      "    accuracy                           0.88      5000\n",
      "   macro avg       0.88      0.88      0.88      5000\n",
      "weighted avg       0.88      0.88      0.88      5000\n",
      "\n",
      "Confusion Matrix (local 20%):\n",
      "TN:2154  FP:346\n",
      "FN:277  TP:2223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 4.1) Create a local train/validation split (80/20)\n",
    "X_text = train_df['text']\n",
    "y_label = train_df['label']\n",
    "\n",
    "X_text_train, X_text_val, y_train, y_val = train_test_split(\n",
    "    X_text, y_label,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y_label\n",
    ")\n",
    "\n",
    "# 4.2) Vectorize those splits\n",
    "X_train_local_tfidf = tfidf_vectorizer.fit_transform(X_text_train)\n",
    "X_val_local_tfidf   = tfidf_vectorizer.transform(X_text_val)\n",
    "\n",
    "# 4.3) Train logistic regression on the 80% training portion\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000, C=1.0, solver='liblinear')\n",
    "clf.fit(X_train_local_tfidf, y_train)\n",
    "\n",
    "# 4.4) Predict + evaluate on local 20% validation\n",
    "y_val_pred = clf.predict(X_val_local_tfidf)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Local validation accuracy: {val_acc:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report (local 20%):\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=['negative','positive']))\n",
    "\n",
    "print(\"Confusion Matrix (local 20%):\")\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "print(f\"TN:{cm[0,0]}  FP:{cm[0,1]}\")\n",
    "print(f\"FN:{cm[1,0]}  TP:{cm[1,1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f13ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on portal’s test.json (locally): 0.8828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 5.1) Refit TF-IDF on entire train set (25000 rows) and retrain classifier\n",
    "X_full_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "clf_full = LogisticRegression(random_state=42, max_iter=1000, C=1.0, solver='liblinear')\n",
    "clf_full.fit(X_full_tfidf, train_df['label'])\n",
    "\n",
    "# 5.2) Transform portal test set and predict\n",
    "X_portal_tfidf = tfidf_vectorizer.transform(test_df['text'])\n",
    "y_portal_pred  = clf_full.predict(X_portal_tfidf)\n",
    "portal_acc     = accuracy_score(test_df['label'], y_portal_pred)\n",
    "\n",
    "print(f\"Accuracy on portal’s test.json (locally): {portal_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dad69de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pipeline saved to skills_assessment.joblib\n"
     ]
    }
   ],
   "source": [
    "# -------------- CELL B: build + save a purely‐standard sklearn pipeline --------------\n",
    "\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\n",
    "        \"tfidf\",\n",
    "        TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            # only keep tokens consisting of letters a–z\n",
    "            token_pattern=r\"(?u)\\b[a-z]+\\b\",\n",
    "            max_features=10000,\n",
    "            stop_words=\"english\",\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.8\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        \"clf\",\n",
    "        LogisticRegression(\n",
    "            random_state=42,\n",
    "            max_iter=1000,\n",
    "            solver=\"liblinear\"\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "# Fit on the RAW \"text\" column (no separate cleaning step!)\n",
    "pipeline.fit(train_df[\"text\"], train_df[\"label\"])\n",
    "\n",
    "# Overwrite the old joblib file:\n",
    "joblib.dump(pipeline, \"skills_assessment.joblib\")\n",
    "print(\"✅ pipeline saved to skills_assessment.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "809ecd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example texts → predicted labels: [('I loved this movie, it was fantastic!', np.int64(1)), ('Worst film ever. I hated every minute.', np.int64(0))]\n",
      "Local test accuracy: 0.88112\n"
     ]
    }
   ],
   "source": [
    "# -------------- CELL C: sanity_check_loaded_model --------------\n",
    "import joblib\n",
    "\n",
    "# 1) Load back the file you just created\n",
    "loaded_pipeline = joblib.load(\"skills_assessment.joblib\")\n",
    "\n",
    "# 2) Try a couple of dummy predictions on RAW text:\n",
    "examples = [\n",
    "    \"I loved this movie, it was fantastic!\",\n",
    "    \"Worst film ever. I hated every minute.\",\n",
    "]\n",
    "\n",
    "# **NO ADDITIONAL CLEANING** — pass the raw strings directly:\n",
    "preds = loaded_pipeline.predict(examples)\n",
    "print(\"Example texts → predicted labels:\", list(zip(examples, preds)))\n",
    "\n",
    "# (Optionally, check .predict_proba or a quick local test on test_df):\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test_pred = loaded_pipeline.predict(test_df[\"text\"])\n",
    "print(\"Local test accuracy:\", accuracy_score(test_df[\"label\"], y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34999c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Uploading model to evaluation portal...\n",
      "Status code: 200\n",
      "{\n",
      "    \"accuracy\": 0.0,\n",
      "    \"metrics\": null,\n",
      "    \"misclassified\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# -------------- CELL D: upload to HTB endpoint --------------\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://10.129.146.230:5000/api/upload\"\n",
    "model_file_path = \"skills_assessment.joblib\"\n",
    "\n",
    "print(\"🚀 Uploading model to evaluation portal...\")\n",
    "with open(model_file_path, \"rb\") as model_file:\n",
    "    response = requests.post(url, files={\"model\": model_file})\n",
    "\n",
    "print(\"Status code:\", response.status_code)\n",
    "print(json.dumps(response.json(), indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22abf74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
